# Server configuration
server:
  host: "127.0.0.1"
  port: 8080
  read_timeout: 30
  write_timeout: 300

# Default target API configuration
default_target:
  base_url: "https://api.deepseek.com"
  path_suffix: "/v1/chat/completions"
  # Set API key via environment variable R2C_DEFAULT_API_KEY or Authorization header
  timeout: 300
  supports_developer_role: true  # DeepSeek supports 'developer' role

# Multi-provider configuration
# Set API keys via environment variables:
# - R2C_PROVIDER_DEEPSEEK_API_KEY
# - R2C_PROVIDER_ZHIPU_API_KEY
# - R2C_PROVIDER_QWEN_API_KEY
# - etc.
providers:
  deepseek:
    base_url: "https://api.deepseek.com"
    path_suffix: "/v1/chat/completions"
    timeout: 300
    supports_developer_role: true  # DeepSeek supports 'developer' role

  zhipu:
    base_url: "https://open.bigmodel.cn/api/coding/paas/v4"
    path_suffix: "/chat/completions"
    timeout: 300

  qwen:
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    path_suffix: "/chat/completions"
    timeout: 300

  ollama:
    base_url: "http://localhost:11434"
    path_suffix: "/v1/chat/completions"
    timeout: 300

  lmstudio:
    base_url: "http://localhost:1234"
    path_suffix: "/v1/chat/completions"
    timeout: 300

  longcat:
    base_url: "https://api.longcat.chat/openai"
    path_suffix: "/v1/chat/completions"
    timeout: 300

  stepfun:
    base_url: "https://api.stepfun.com/v1"
    path_suffix: "/chat/completions"
    timeout: 300

  deepinfra:
    base_url: "https://api.deepinfra.com/v1/openai"
    path_suffix: "/chat/completions"
    timeout: 300

# Logging configuration
logging:
  level: "debug"
  format: "text"

# Model mapping (optional)
# Maps Codex model names to target provider model names
model_mapping:
  "gpt-4": "deepseek-chat"
  "gpt-4o": "deepseek-chat"
  "gpt-4-turbo": "deepseek-chat"
  "o1": "deepseek-reasoner"
  "o3-mini": "deepseek-reasoner"

# Storage configuration for multi-turn conversation support
storage:
  path: "./data/conversations.db"

# Web Search configuration for tool interception
# Enable web_search tool support for third-party LLM providers
# Set API keys via environment variables:
# - R2C_WEB_SEARCH_PROVIDERS_ZHIPU_API_KEY
# - R2C_WEB_SEARCH_PROVIDERS_FIRECRAWL_API_KEY
# - R2C_WEB_SEARCH_PROVIDERS_TAVILY_API_KEY (example)
web_search:
  enabled: true
  default: "zhipu"  # Default provider to use
  providers:
    # MCP Type - Generic implementation for MCP-compatible services
    zhipu:
      type: "mcp"
      base_url: "https://open.bigmodel.cn/api/mcp/web_search_prime/mcp"
      api_key: ""
      tool_name: "webSearchPrime"      # MCP tool name
      query_param: "search_query"      # Query parameter name
      timeout: 30

    # Additional MCP providers can be added without code changes
    # tavily:
    #   type: "mcp"
    #   base_url: "https://api.tavily.com/mcp"
    #   api_key: ""
    #   tool_name: "search"
    #   query_param: "query"
    #   timeout: 30

    # exa:
    #   type: "mcp"
    #   base_url: "https://api.exa.ai/mcp"
    #   api_key: ""
    #   tool_name: "web_search"
    #   query_param: "query"
    #   timeout: 30

    # Firecrawl Type - Specialized implementation
    firecrawl:
      type: "firecrawl"
      base_url: "https://api.firecrawl.dev/v2"
      api_key: ""
      timeout: 30
      max_results: 5
